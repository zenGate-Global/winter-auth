import {
	RekognitionClient,
	DetectFacesCommand,
	CompareFacesCommand,
	type DetectFacesCommandInput,
	type CompareFacesCommandInput,
	type Face,
	type ComparedFace
} from '@aws-sdk/client-rekognition';
import { BaseFaceRecognitionProvider, type ProviderConfig } from './base-provider';
import type {
  ImageQualityResult,
  ImageVerificationResult,
  LiveVideoVerificationResult,
  SecurityStrength,
  VerificationStatus,
  WinterAuthError
} from '../types';
import { SecurityStrength as SecurityStrengthEnum } from '../types';

/**
 * AWS Rekognition Face Recognition Provider
 * Implements face recognition using AWS Rekognition API with official AWS SDK
 */
export class AWSRekognitionProvider extends BaseFaceRecognitionProvider {
  public readonly name = 'aws';
  
  private rekognitionClient?: RekognitionClient;
  private accessKeyId?: string;
  private secretAccessKey?: string;
  private region?: string;

  /**
   * Initialize the AWS Rekognition provider with credentials
   */
  async initialize(config: ProviderConfig): Promise<void> {
    try {
      // Extract AWS credentials from config
      this.accessKeyId = config.accessKeyId || config.apiKey;
      this.secretAccessKey = config.secretAccessKey;
      this.region = config.region || 'us-east-1';
      
      // Validate required credentials
      if (!this.accessKeyId || !this.secretAccessKey) {
        throw new Error('AWS credentials are required: accessKeyId and secretAccessKey must be provided in config');
      }

      // Initialize AWS Rekognition client with proper credentials
      this.rekognitionClient = new RekognitionClient({
        region: this.region,
        credentials: {
          accessKeyId: this.accessKeyId,
          secretAccessKey: this.secretAccessKey
        }
      });

      // Test the connection with a simple call
      await this.testConnection();
      
      this._isInitialized = true;
    } catch (error) {
      this._isInitialized = false;
      throw new Error(`AWS Rekognition initialization failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  /**
   * Test AWS Rekognition connection by calling a simple API
   */
  private async testConnection(): Promise<void> {
    try {
      // Create a minimal test image (1x1 pixel base64 PNG)
      const testImageBase64 = 'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNkYPhfDwAChwGA60e6kgAAAABJRU5ErkJggg==';
      const testImageBytes = Buffer.from(testImageBase64, 'base64');
      
      const params: DetectFacesCommandInput = {
        Image: {
          Bytes: testImageBytes
        },
        Attributes: ['DEFAULT']
      };

      // This should fail gracefully (no faces in 1px image) but validates credentials
      await this.rekognitionClient!.send(new DetectFacesCommand(params));
    } catch (error: any) {
      // If it's a credentials error, re-throw
      if (error?.name === 'UnauthorizedOperation' || 
          error?.name === 'InvalidAccessKeyId' || 
          error?.name === 'SignatureDoesNotMatch' ||
          error?.message?.includes('signature') ||
          error?.message?.includes('credentials')) {
        throw error;
      }
      // Other errors (like no faces detected) are expected and OK
    }
  }
      console.log(`✅ AWS Rekognition provider initialized successfully (region: ${this.region})`);
    } catch (error) {
      throw new Error(`AWS Rekognition initialization failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  async checkImageQuality(
    imageInput: string | HTMLCanvasElement | HTMLImageElement | File | Blob
  ): Promise<ImageQualityResult> {
    this.ensureInitialized();
    
    try {
      const imageBytes = await this.imageToBase64(imageInput);
      
      // Use AWS Rekognition DetectFaces to analyze image quality
      const response = await this.callAWSAPI('DetectFaces', {
        Image: {
          Bytes: imageBytes
        },
        Attributes: ['ALL']
      });
      
      const faces = response.FaceDetails || [];
      
      if (faces.length === 0) {
        return {
          isGoodQuality: false,
          score: 0,
          issues: [{
            code: 'NO_FACE_DETECTED',
            message: 'No face detected in the image',
            timestamp: Date.now()
          }],
          details: {
            faceCount: 0,
            resolution: { width: 0, height: 0 }
          }
        };
      }
      
      if (faces.length > 1) {
        return {
          isGoodQuality: false,
          score: 30,
          issues: [{
            code: 'MULTIPLE_FACES_DETECTED',
            message: `Multiple faces detected: ${faces.length} faces`,
            timestamp: Date.now()
          }],
          details: {
            faceCount: faces.length,
            resolution: { width: 0, height: 0 }
          }
        };
      }
      
      const face = faces[0];
      const confidence = face.Confidence || 0;
      const quality = face.Quality || {};
      const brightness = quality.Brightness || 0;
      const sharpness = quality.Sharpness || 0;
      
      // Calculate overall quality score
      const qualityScore = Math.round((confidence + brightness + sharpness) / 3);
      const isGoodQuality = qualityScore >= 70 && confidence >= 80;
      
      const issues: WinterAuthError[] = [];
      if (confidence < 80) {
        issues.push({
          code: 'LOW_FACE_CONFIDENCE',
          message: `Low face detection confidence: ${confidence.toFixed(1)}%`,
          timestamp: Date.now()
        });
      }
      if (brightness < 40) {
        issues.push({
          code: 'LOW_BRIGHTNESS',
          message: `Image too dark: brightness ${brightness.toFixed(1)}`,
          timestamp: Date.now()
        });
      }
      if (sharpness < 40) {
        issues.push({
          code: 'LOW_SHARPNESS',
          message: `Image too blurry: sharpness ${sharpness.toFixed(1)}`,
          timestamp: Date.now()
        });
      }
      
      return {
        isGoodQuality,
        score: qualityScore,
        issues,
        details: {
          faceCount: 1,
          faceConfidence: confidence,
          resolution: { width: 0, height: 0 }, // AWS doesn't provide image dimensions
          brightness,
          contrast: 0, // AWS doesn't provide contrast
          blur: 100 - sharpness, // Convert sharpness to blur
          headPose: face.Pose?.Yaw || 0
        }
      };
      
    } catch (error) {
      throw new Error(`AWS Rekognition quality check failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  async compareByImage(
    referenceImage: string | HTMLCanvasElement | HTMLImageElement | File | Blob,
    targetImage: string | HTMLCanvasElement | HTMLImageElement | File | Blob,
    options?: { securityLevel?: SecurityStrength }
  ): Promise<ImageVerificationResult> {
    this.ensureInitialized();
    const startTime = Date.now();
    
    try {
      const securityLevel = options?.securityLevel || SecurityStrengthEnum.MEDIUM;
      
      // Convert images to base64
      const [refImageBytes, targetImageBytes] = await Promise.all([
        this.imageToBase64(referenceImage),
        this.imageToBase64(targetImage)
      ]);
      
      // Check quality of both images
      const [qualityResult] = await Promise.all([
        this.checkImageQuality(targetImage)
      ]);
      
      // Use AWS Rekognition CompareFaces API
      const response = await this.callAWSAPI('CompareFaces', {
        SourceImage: {
          Bytes: refImageBytes
        },
        TargetImage: {
          Bytes: targetImageBytes
        },
        SimilarityThreshold: this.getAWSSimilarityThreshold(securityLevel)
      });
      
      const faceMatches = response.FaceMatches || [];
      const similarity = faceMatches.length > 0 ? (faceMatches[0].Similarity || 0) / 100 : 0;
      const threshold = this.getSecurityThreshold(securityLevel);
      const isMatch = similarity >= threshold;
      const confidence = similarity;
      
      const comparisonResult = {
        isMatch,
        similarity,
        similarityPercent: Math.round(similarity * 100),
        confidence,
        threshold,
        processingTime: Date.now() - startTime
      };
      
      const verified = qualityResult.isGoodQuality && isMatch;
      
      return {
        verified,
        isMatch,
        confidence,
        similarity,
        similarityPercent: comparisonResult.similarityPercent,
        qualityResult,
        comparisonResult,
        processingTime: Date.now() - startTime,
        timestamp: Date.now()
      };
      
    } catch (error) {
      const err: WinterAuthError = {
        code: 'FACE_COMPARISON_FAILED',
        message: `AWS Rekognition comparison failed: ${error instanceof Error ? error.message : 'Unknown error'}`,
        timestamp: Date.now()
      };
      
      return {
        verified: false,
        isMatch: false,
        confidence: 0,
        similarity: 0,
        similarityPercent: 0,
        qualityResult: {
          isGoodQuality: false,
          score: 0,
          issues: [],
          details: {
            faceCount: 0,
            resolution: { width: 0, height: 0 }
          }
        },
        comparisonResult: {
          isMatch: false,
          similarity: 0,
          similarityPercent: 0,
          confidence: 0,
          threshold: 0,
          processingTime: 0
        },
        error: err,
        processingTime: Date.now() - startTime,
        timestamp: Date.now()
      };
    }
  }

  async compareByLiveVideo(
    referenceImage: string | HTMLCanvasElement | HTMLImageElement | File | Blob,
    videoElement: HTMLVideoElement,
    options?: {
      securityLevel?: SecurityStrength;
      enableLivenessCheck?: boolean;
      enableChallenges?: boolean;
      onProgress?: (progress: { stage: string; progress: number; feedback: string }) => void;
    }
  ): Promise<LiveVideoVerificationResult> {
    this.ensureInitialized();
    const startTime = Date.now();
    
    const {
      securityLevel = SecurityStrengthEnum.MEDIUM,
      enableLivenessCheck = true,
      enableChallenges = false, // AWS doesn't handle challenges - would need separate implementation
      onProgress
    } = options || {};
    
    const reportProgress = (stage: string, progress: number, feedback: string) => {
      onProgress?.({ stage, progress, feedback });
    };
    
    try {
      // Stage 1: Reference Image Quality Check
      reportProgress('setup', 10, 'Checking reference image quality...');
      const qualityResult = await this.checkImageQuality(referenceImage);
      
      if (!qualityResult.isGoodQuality) {
        return this.createVideoResult(VerificationStatus.FAILED, false, {
          qualityResult,
          error: {
            code: 'QUALITY_CHECK_FAILED',
            message: 'Reference image has poor quality',
            timestamp: Date.now()
          },
          processingTime: Date.now() - startTime,
          securityLevel
        });
      }
      
      // Stage 2: Liveness Check (if enabled)
      if (enableLivenessCheck) {
        reportProgress('liveness_check', 30, 'Performing liveness check...');
        
        try {
          const livenessResult = await this.performLivenessCheck(videoElement);
          if (!livenessResult.isLive) {
            return this.createVideoResult(VerificationStatus.FAILED, false, {
              livenessResult,
              error: {
                code: 'LIVENESS_CHECK_FAILED',
                message: 'Liveness check failed',
                timestamp: Date.now()
              },
              processingTime: Date.now() - startTime,
              securityLevel
            });
          }
        } catch (error) {
          console.warn('⚠️ Liveness check failed, continuing without it:', error);
        }
      }
      
      // Stage 3: Face Comparison with video frames
      reportProgress('face_comparison', 60, 'Comparing faces with video stream...');
      
      const frameResults: { similarity: number; isMatch: boolean }[] = [];
      const SAMPLE_COUNT = 10;
      const SAMPLE_INTERVAL = 200;
      
      for (let i = 0; i < SAMPLE_COUNT; i++) {
        const canvas = this.createCanvasFromVideo(videoElement);
        
        try {
          const frameComparison = await this.compareByImage(referenceImage, canvas, { securityLevel });
          frameResults.push({
            similarity: frameComparison.similarity,
            isMatch: frameComparison.isMatch
          });
        } catch (error) {
          console.warn(`Frame ${i + 1} comparison failed:`, error);
          frameResults.push({ similarity: 0, isMatch: false });
        }
        
        await new Promise(resolve => setTimeout(resolve, SAMPLE_INTERVAL));
      }
      
      // Stage 4: Calculate overall result
      reportProgress('finalizing', 90, 'Finalizing verification...');
      
      const successfulMatches = frameResults.filter(r => r.isMatch).length;
      const averageSimilarity = frameResults.length > 0 
        ? frameResults.reduce((sum, r) => sum + r.similarity, 0) / frameResults.length 
        : 0;
      
      // Require at least 60% of frames to match
      const overallMatch = successfulMatches / SAMPLE_COUNT >= 0.6;
      
      const comparisonResult = {
        isMatch: overallMatch,
        similarity: averageSimilarity,
        similarityPercent: Math.round(averageSimilarity * 100),
        confidence: averageSimilarity,
        threshold: this.getSecurityThreshold(securityLevel),
        processingTime: Date.now() - startTime,
        framesAnalyzed: SAMPLE_COUNT,
        successfulMatches,
        averageSimilarity
      };
      
      return this.createVideoResult(
        overallMatch ? VerificationStatus.SUCCESS : VerificationStatus.FAILED, 
        overallMatch, 
        {
          confidence: averageSimilarity,
          similarity: averageSimilarity,
          qualityResult,
          comparisonResult,
          framesAnalyzed: SAMPLE_COUNT,
          processingTime: Date.now() - startTime,
          securityLevel
        }
      );
      
    } catch (error) {
      return this.createVideoResult(VerificationStatus.ERROR, false, {
        error: {
          code: 'LIVE_VIDEO_FAILED',
          message: `Live video verification failed: ${error instanceof Error ? error.message : 'Unknown error'}`,
          timestamp: Date.now()
        },
        processingTime: Date.now() - startTime,
        securityLevel
      });
    }
  }

  async dispose(): Promise<void> {
    this._isInitialized = false;
    console.log('🗑️ AWS Rekognition provider disposed');
  }

  /**
   * Test AWS connection with a simple API call
   */
  private async testConnection(): Promise<void> {
    // Create a simple test with DetectFaces to verify credentials
    const testImageBase64 = '/9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAABAAEDASIAAhEBAxEB/8QAFQABAQAAAAAAAAAAAAAAAAAAAAv/xAAUEAEAAAAAAAAAAAAAAAAAAAAA/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAX/xAAUEQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIRAxEAPwCdABmX/9k='; // 1x1 pixel JPEG
    
    try {
      await this.callAWSAPI('DetectFaces', {
        Image: {
          Bytes: testImageBase64
        }
      });
    } catch (error) {
      // If it's a validation error about the image, that's fine - connection works
      if (error instanceof Error) {
        if (error.message.includes('InvalidImageFormatException') || 
            error.message.includes('InvalidS3ObjectException') ||
            error.message.includes('ImageTooSmallException')) {
          return; // Connection is working
        }
      }
      throw error;
    }
  }

  /**
   * Perform liveness check using basic motion detection
   * Note: This is a simplified implementation - real Face Liveness requires session management
   */
  private async performLivenessCheck(videoElement: HTMLVideoElement): Promise<{ isLive: boolean; confidence: number }> {
    // For now, we'll use a basic motion detection approach
    // AWS Face Liveness requires a more complex session-based implementation
    
    const frames: ImageData[] = [];
    const canvas = document.createElement('canvas');
    const ctx = canvas.getContext('2d');
    
    if (!ctx) throw new Error('Could not get canvas context');
    
    canvas.width = videoElement.videoWidth;
    canvas.height = videoElement.videoHeight;
    
    // Capture 3 frames with small delays
    for (let i = 0; i < 3; i++) {
      ctx.drawImage(videoElement, 0, 0);
      frames.push(ctx.getImageData(0, 0, canvas.width, canvas.height));
      await new Promise(resolve => setTimeout(resolve, 100));
    }
    
    // Calculate motion between frames (basic implementation)
    let totalDifference = 0;
    const pixelCount = frames[0].data.length;
    
    for (let i = 1; i < frames.length; i++) {
      for (let j = 0; j < pixelCount; j += 4) {
        const diff = Math.abs(frames[i].data[j] - frames[i-1].data[j]);
        totalDifference += diff;
      }
    }
    
    const averageDifference = totalDifference / (pixelCount * (frames.length - 1));
    const isLive = averageDifference > 2; // Basic threshold for motion detection
    
    return {
      isLive,
      confidence: Math.min(averageDifference / 10, 1) // Normalize to 0-1
    };
  }

  /**
   * Create canvas from video element
   */
  private createCanvasFromVideo(videoElement: HTMLVideoElement): HTMLCanvasElement {
    const canvas = document.createElement('canvas');
    canvas.width = videoElement.videoWidth;
    canvas.height = videoElement.videoHeight;
    const ctx = canvas.getContext('2d');
    if (!ctx) throw new Error('Could not get 2D context from canvas');
    ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
    return canvas;
  }

  /**
   * Create standardized video result
   */
  private createVideoResult(
    status: VerificationStatus, 
    verified: boolean, 
    details: Partial<LiveVideoVerificationResult>
  ): LiveVideoVerificationResult {
    return {
      verified,
      isMatch: verified,
      status,
      confidence: details.confidence || 0,
      similarity: details.similarity || 0,
      framesAnalyzed: details.framesAnalyzed || 0,
      processingTime: details.processingTime || 0,
      securityLevel: details.securityLevel || SecurityStrengthEnum.MEDIUM,
      timestamp: Date.now(),
      ...details
    };
  }

  /**
   * Make authenticated API call to AWS Rekognition using axios
   */
  private async callAWSAPI(operation: string, payload: any): Promise<any> {
    const headers = await this.createAWSHeaders(operation, payload);
    
    try {
      const response = await this.axiosInstance.post('/', payload, { headers });
      return response.data;
    } catch (error) {
      if (axios.isAxiosError(error)) {
        const errorData = error.response?.data;
        const statusCode = error.response?.status;
        const errorMessage = errorData?.message || error.message;
        
        throw new Error(`AWS API call failed (${statusCode}): ${errorMessage}`);
      }
      throw error;
    }
  }

  /**
   * Create AWS signature headers for authentication
   */
  private async createAWSHeaders(operation: string, payload: any): Promise<Record<string, string>> {
    const now = new Date();
    const datestamp = now.toISOString().slice(0, 10).replace(/-/g, '');
    const timestamp = now.toISOString().slice(0, 19).replace(/[-:]/g, '') + 'Z';
    
    return {
      'X-Amz-Target': `RekognitionService.${operation}`,
      'X-Amz-Date': timestamp,
      'Authorization': await this.createAuthorizationHeader(payload, timestamp, datestamp)
    };
  }

  /**
   * Create AWS authorization header (simplified - for production use AWS SDK)
   */
  private async createAuthorizationHeader(
    payload: any, 
    timestamp: string, 
    datestamp: string
  ): Promise<string> {
    // This is a simplified implementation
    // For production, use the AWS SDK which handles all the signing complexity
    const payloadHash = await this.sha256(JSON.stringify(payload));
    
    return `AWS4-HMAC-SHA256 Credential=${this.accessKeyId}/${datestamp}/${this.region}/rekognition/aws4_request, SignedHeaders=content-type;host;x-amz-date;x-amz-target, Signature=${payloadHash.slice(0, 16)}`;
  }

  /**
   * Simple SHA256 hash (in production, use proper AWS signing)
   */
  private async sha256(message: string): Promise<string> {
    const msgBuffer = new TextEncoder().encode(message);
    const hashBuffer = await crypto.subtle.digest('SHA-256', msgBuffer);
    const hashArray = Array.from(new Uint8Array(hashBuffer));
    return hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
  }

  /**
   * Get AWS similarity threshold based on security level
   */
  private getAWSSimilarityThreshold(securityLevel: SecurityStrength): number {
    const thresholds = {
      [SecurityStrengthEnum.LOW]: 60,
      [SecurityStrengthEnum.MEDIUM]: 70,
      [SecurityStrengthEnum.HIGH]: 80,
      [SecurityStrengthEnum.MAXIMUM]: 90
    };
    return thresholds[securityLevel];
  }

  /**
   * Get security threshold as 0-1 value
   */
  private getSecurityThreshold(securityLevel: SecurityStrength): number {
    return this.getAWSSimilarityThreshold(securityLevel) / 100;
  }

  /**
   * Get environment variable with optional fallback
   */
  private getEnvironmentVariable(name: string, fallback?: string): string {
    // Try multiple sources for environment variables
    const value = 
      process.env[name] || // Node.js
      (globalThis as any)?.[name] || // Browser global
      (typeof window !== 'undefined' && (window as any)[name]); // Browser window
    
    if (!value) {
      if (fallback !== undefined) {
        return fallback;
      }
      throw new Error(`Environment variable ${name} is required`);
    }
    
    return value;
  }
}